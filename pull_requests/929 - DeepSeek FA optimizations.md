## ðŸ”€ [Pull Request #929](https://github.com/ikawrakow/ik_llama.cpp/pull/929) - DeepSeek FA optimizations

| **Author** | `ikawrakow` |
| :--- | :--- |
| **State** | âœ… **Open** |
| **Source Branch** | `ik/deepseek_fa_opt` |
| **Target Branch** | `main` |
| **Created** | 2025-11-09 |

---

## ðŸ“„ Description

This PR improves PP and TG performance for DeepSeek models.

With DeepSeek-Lite fully offloaded to my RTX-4080 GPU I see compared to the main branch
* About 6% (short context) to 13% (context of 65k tokens) improvement for PP
* About 3% (short context) to 7% (context of 65k tokens) improvement for TG

Impact will be lower for hybrid inference. For this model with all MoE tensors left on the CPU I see a ~10% PP and ~2% TG improvement at 65k tokens, but not sure how representative this is for the giant DeepSeek-R1/V3 or Kimi2-1T models.

Here some `sweep-bench` results for DeepSeek-Lite on RTX-4080 using
```
./bin/llama-sweep-bench -m $model -t 1 -ngl 100 -b 4096 -ub 4096 -n 256 -mla 3 -cuda fusion=1
```

### Main branch

|    PP |     TG |   N_KV |   T_PP s | S_PP t/s |   T_TG s | S_TG t/s |
|-------|--------|--------|----------|----------|----------|----------|
|  4096 |    256 |      0 |    0.392 | 10444.69 |    1.041 |   245.80 |
|  4096 |    256 |   4096 |    0.452 |  9058.08 |    1.112 |   230.29 |
|  4096 |    256 |   8192 |    0.540 |  7582.33 |    1.157 |   221.33 |
|  4096 |    256 |  12288 |    0.631 |  6490.97 |    1.217 |   210.27 |
|  4096 |    256 |  16384 |    0.725 |  5653.54 |    1.305 |   196.15 |
|  4096 |    256 |  20480 |    0.823 |  4975.37 |    1.490 |   171.78 |
|  4096 |    256 |  24576 |    0.906 |  4518.61 |    1.499 |   170.73 |
|  4096 |    256 |  28672 |    1.002 |  4088.54 |    1.518 |   168.66 |
|  4096 |    256 |  32768 |    1.091 |  3755.50 |    1.557 |   164.41 |
|  4096 |    256 |  36864 |    1.182 |  3465.94 |    1.613 |   158.74 |
|  4096 |    256 |  40960 |    1.273 |  3218.16 |    1.760 |   145.42 |
|  4096 |    256 |  45056 |    1.370 |  2988.83 |    1.772 |   144.45 |
|  4096 |    256 |  49152 |    1.461 |  2802.97 |    1.787 |   143.25 |
|  4096 |    256 |  53248 |    1.553 |  2637.17 |    1.828 |   140.04 |
|  4096 |    256 |  57344 |    1.649 |  2483.75 |    1.879 |   136.27 |
|  4096 |    256 |  61440 |    1.738 |  2357.28 |    2.014 |   127.14 |

### PR

|    PP |     TG |   N_KV |   T_PP s | S_PP t/s |   T_TG s | S_TG t/s |
|-------|--------|--------|----------|----------|----------|----------|
|  4096 |    256 |      0 |    0.368 | 11142.79 |    1.013 |   252.70 |
|  4096 |    256 |   4096 |    0.411 |  9969.96 |    1.095 |   233.76 |
|  4096 |    256 |   8192 |    0.488 |  8393.36 |    1.137 |   225.25 |
|  4096 |    256 |  12288 |    0.566 |  7235.67 |    1.194 |   214.40 |
|  4096 |    256 |  16384 |    0.647 |  6331.93 |    1.368 |   187.10 |
|  4096 |    256 |  20480 |    0.726 |  5640.24 |    1.411 |   181.48 |
|  4096 |    256 |  24576 |    0.809 |  5061.59 |    1.422 |   180.02 |
|  4096 |    256 |  28672 |    0.891 |  4595.82 |    1.455 |   175.99 |
|  4096 |    256 |  32768 |    0.966 |  4238.19 |    1.590 |   160.96 |
|  4096 |    256 |  36864 |    1.047 |  3913.22 |    1.632 |   156.90 |
|  4096 |    256 |  40960 |    1.127 |  3633.31 |    1.643 |   155.78 |
|  4096 |    256 |  45056 |    1.210 |  3385.91 |    1.667 |   153.59 |
|  4096 |    256 |  49152 |    1.291 |  3171.66 |    1.796 |   142.56 |
|  4096 |    256 |  53248 |    1.376 |  2976.82 |    1.843 |   138.87 |
|  4096 |    256 |  57344 |    1.458 |  2808.88 |    1.857 |   137.84 |
|  4096 |    256 |  61440 |    1.541 |  2658.79 |    1.886 |   135.76 |

### llama.cpp (tag: b6993)

|    PP |     TG |   N_KV |   T_PP s | S_PP t/s |   T_TG s | S_TG t/s |
|-------|--------|--------|----------|----------|----------|----------|
|  4096 |    256 |      0 |    0.581 |  7054.33 |    1.050 |   243.79 |
|  4096 |    256 |   4096 |    0.769 |  5324.63 |    1.137 |   225.12 |
|  4096 |    256 |   8192 |    0.988 |  4143.87 |    1.202 |   212.93 |
|  4096 |    256 |  12288 |    1.210 |  3384.50 |    1.288 |   198.72 |
|  4096 |    256 |  16384 |    1.431 |  2861.41 |    1.393 |   183.83 |
|  4096 |    256 |  20480 |    1.672 |  2450.08 |    1.593 |   160.68 |
|  4096 |    256 |  24576 |    1.898 |  2157.58 |    1.614 |   158.60 |
|  4096 |    256 |  28672 |    2.120 |  1932.27 |    1.646 |   155.56 |
|  4096 |    256 |  32768 |    2.349 |  1743.83 |    1.703 |   150.34 |
|  4096 |    256 |  36864 |    2.542 |  1611.58 |    1.770 |   144.66 |
|  4096 |    256 |  40960 |    2.765 |  1481.36 |    1.925 |   132.96 |
|  4096 |    256 |  45056 |    3.018 |  1357.06 |    1.943 |   131.74 |
|  4096 |    256 |  49152 |    3.206 |  1277.59 |    1.975 |   129.61 |
|  4096 |    256 |  53248 |    3.437 |  1191.80 |    2.035 |   125.78 |
|  4096 |    256 |  57344 |    3.677 |  1113.85 |    2.100 |   121.89 |
|  4096 |    256 |  61440 |    3.967 |  1032.52 |    2.252 |   113.69 |